"""
æ£€æµ‹è¯¯å·®å½±å“åˆ†æå™¨
åˆ†æä¸åŒÏƒï¼ˆæ£€æµ‹è¯¯å·®ï¼‰æ°´å¹³å¯¹BMIåˆ†ç»„å’Œæ—¶ç‚¹æ¨èçš„å½±å“
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple, Any
import yaml
import os
import sys
from datetime import datetime

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥ç°æœ‰æ¨¡å—
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', 'src'))

from empirical_model import EmpiricalDetectionModel
from io_utils import load_step1_products, load_step2_config

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


class ErrorImpactAnalyzer:
    """æ£€æµ‹è¯¯å·®å½±å“åˆ†æå™¨"""
    
    def __init__(self, config_path: str = None):
        """
        åˆå§‹åŒ–è¯¯å·®å½±å“åˆ†æå™¨
        
        Parameters:
        -----------
        config_path : str
            é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_path)
        self.empirical_model = None
        self.baseline_sigma = None
        self.bmi_groups = None
        self.analysis_results = {}
        
        # è®¾ç½®Ïƒæƒ…æ™¯å€æ•°ï¼ˆæ‰©å¤§èŒƒå›´ä»¥æ˜¾ç¤ºæ›´æ˜æ˜¾çš„å½±å“ï¼‰
        self.sigma_multipliers = [0.1, 0.5, 1.0, 2.0, 5.0]
        
        print("âœ… è¯¯å·®å½±å“åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if config_path is None:
            config_path = os.path.join(os.path.dirname(__file__), '..', '..', 'config', 'step2_config.yaml')
        
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            return config
        except Exception as e:
            print(f"âš ï¸ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'grouping': {
                'custom_cuts': [20.0, 30.5, 32.7, 34.4, 50.0]
            },
            'model_params': {
                'alpha': 11.358,
                'beta': -24.261,
                'gamma': 0.5,
                'delta': 0.01
            }
        }
    
    def load_data_and_model(self, data_dir: str = None):
        """
        åŠ è½½æ•°æ®å’Œæ¨¡å‹
        
        Parameters:
        -----------
        data_dir : str
            æ•°æ®ç›®å½•è·¯å¾„
        """
        if data_dir is None:
            data_dir = os.path.join(os.path.dirname(__file__), '..', '..', '..', 'step2_1')
        
        print("ğŸ“Š åŠ è½½æ•°æ®å’Œæ¨¡å‹...")
        
        try:
            # åŠ è½½Step1æ•°æ®
            self.long_df, self.surv_df, self.report_df, self.step1_config = load_step1_products(data_dir)
            print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(self.long_df)} æ¡è®°å½•")
            
            # åˆ›å»ºç»éªŒæ¨¡å‹
            self.empirical_model = EmpiricalDetectionModel(
                alpha=self.config['model_params']['alpha'],
                beta=self.config['model_params']['beta'],
                gamma=self.config['model_params']['gamma'],
                delta=self.config['model_params']['delta']
            )
            
            # è·å–åŸºå‡†Ïƒ
            self.baseline_sigma = self._extract_baseline_sigma()
            print(f"âœ… åŸºå‡†Ïƒ: {self.baseline_sigma:.6f}")
            
            # è®¾ç½®BMIåˆ†ç»„
            self._setup_bmi_groups()
            print(f"âœ… BMIåˆ†ç»„è®¾ç½®å®Œæˆ: {len(self.bmi_groups)} ä¸ªç»„")
            
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise
    
    def _extract_baseline_sigma(self) -> float:
        """ä»æŠ¥å‘Šä¸­æå–åŸºå‡†Ïƒ"""
        try:
            # å°è¯•ä»æŠ¥å‘Šä¸­æå–Ïƒ
            if 'sigma_global' in self.report_df.columns:
                return self.report_df['sigma_global'].iloc[0]
            elif 'global_sigma' in self.report_df.columns:
                return self.report_df['global_sigma'].iloc[0]
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤å€¼
                print("âš ï¸ æœªæ‰¾åˆ°åŸºå‡†Ïƒï¼Œä½¿ç”¨é»˜è®¤å€¼ 0.005857")
                return 0.005857
        except:
            print("âš ï¸ æ— æ³•æå–åŸºå‡†Ïƒï¼Œä½¿ç”¨é»˜è®¤å€¼ 0.005857")
            return 0.005857
    
    def _setup_bmi_groups(self):
        """è®¾ç½®BMIåˆ†ç»„"""
        cuts = self.config['grouping']['custom_cuts']
        labels = ['ä½BMIç»„', 'ä¸­BMIç»„', 'é«˜BMIç»„', 'æé«˜BMIç»„']
        
        self.bmi_groups = {}
        for i, (label, (cut_min, cut_max)) in enumerate(zip(labels, zip(cuts[:-1], cuts[1:]))):
            # è®¡ç®—ç»„å†…BMIä¸­ä½æ•°
            group_data = self.long_df[
                (self.long_df['BMI_used'] >= cut_min) & 
                (self.long_df['BMI_used'] < cut_max)
            ]
            bmi_median = group_data['BMI_used'].median() if len(group_data) > 0 else (cut_min + cut_max) / 2
            
            self.bmi_groups[label] = {
                'bmi_range': (cut_min, cut_max),
                'bmi_median': bmi_median,
                'sample_size': len(group_data)
            }
    
    def run_error_impact_analysis(self) -> Dict:
        """
        è¿è¡Œè¯¯å·®å½±å“åˆ†æ
        
        Returns:
        --------
        Dict
            åˆ†æç»“æœ
        """
        print("ğŸ” å¼€å§‹è¯¯å·®å½±å“åˆ†æ...")
        
        # 1. è®¡ç®—ä¸åŒÏƒä¸‹çš„æ¨èæ—¶ç‚¹
        time_recommendations = self._calculate_time_recommendations()
        
        # 2. è®¡ç®—é£é™©å‡½æ•°ä¿®æ­£
        risk_analysis = self._analyze_risk_function_impact()
        
        # 3. æ•æ„Ÿæ€§åˆ†æ
        sensitivity_analysis = self._run_sensitivity_analysis()
        
        # 4. ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
        comparison_table = self._generate_comparison_table(time_recommendations)
        
        # 5. ç”Ÿæˆå¯è§†åŒ–
        self._create_visualizations(time_recommendations, sensitivity_analysis)
        
        # æ•´åˆç»“æœ
        self.analysis_results = {
            'time_recommendations': time_recommendations,
            'risk_analysis': risk_analysis,
            'sensitivity_analysis': sensitivity_analysis,
            'comparison_table': comparison_table,
            'baseline_sigma': self.baseline_sigma,
            'sigma_multipliers': self.sigma_multipliers
        }
        
        print("âœ… è¯¯å·®å½±å“åˆ†æå®Œæˆ")
        return self.analysis_results
    
    def _calculate_time_recommendations(self) -> Dict:
        """è®¡ç®—ä¸åŒÏƒä¸‹çš„æ¨èæ—¶ç‚¹"""
        print("ğŸ“… è®¡ç®—æ¨èæ—¶ç‚¹...")
        
        recommendations = {}
        
        for multiplier in self.sigma_multipliers:
            sigma = self.baseline_sigma * multiplier
            sigma = max(sigma, 0.001)  # è®¾ç½®Ïƒä¸‹é™ï¼Œé¿å…é™¤é›¶
            
            group_times = {}
            for group_name, group_info in self.bmi_groups.items():
                bmi_median = group_info['bmi_median']
                optimal_time = self.empirical_model.predict_optimal_time(bmi_median, sigma)
                group_times[group_name] = {
                    'bmi_median': bmi_median,
                    'optimal_time': optimal_time,
                    'sigma': sigma
                }
            
            recommendations[f'sigma_{multiplier}x'] = {
                'sigma': sigma,
                'multiplier': multiplier,
                'group_times': group_times
            }
        
        return recommendations
    
    def _analyze_risk_function_impact(self) -> Dict:
        """åˆ†æé£é™©å‡½æ•°å½±å“"""
        print("âš ï¸ åˆ†æé£é™©å‡½æ•°å½±å“...")
        
        risk_analysis = {}
        
        for multiplier in self.sigma_multipliers:
            sigma = self.baseline_sigma * multiplier
            sigma = max(sigma, 0.001)
            
            group_risks = {}
            for group_name, group_info in self.bmi_groups.items():
                bmi_median = group_info['bmi_median']
                
                # è®¡ç®—è€ƒè™‘Ïƒçš„é£é™©
                risk_with_sigma = self._calculate_risk_with_sigma(bmi_median, sigma)
                
                # è®¡ç®—ä¸è€ƒè™‘Ïƒçš„é£é™©ï¼ˆåŸºå‡†ï¼‰
                risk_baseline = self._calculate_risk_with_sigma(bmi_median, 0.0)
                
                group_risks[group_name] = {
                    'risk_with_sigma': risk_with_sigma,
                    'risk_baseline': risk_baseline,
                    'risk_change': risk_with_sigma - risk_baseline,
                    'risk_change_ratio': (risk_with_sigma - risk_baseline) / risk_baseline if risk_baseline > 0 else 0
                }
            
            risk_analysis[f'sigma_{multiplier}x'] = {
                'sigma': sigma,
                'multiplier': multiplier,
                'group_risks': group_risks
            }
        
        return risk_analysis
    
    def _calculate_risk_with_sigma(self, bmi: float, sigma: float) -> float:
        """
        è®¡ç®—è€ƒè™‘Ïƒçš„é£é™©å‡½æ•°
        
        Parameters:
        -----------
        bmi : float
            BMIå€¼
        sigma : float
            æ£€æµ‹è¯¯å·®Ïƒ
            
        Returns:
        --------
        float
            é£é™©å€¼
        """
        # è·å–æ¨èæ—¶ç‚¹
        optimal_time = self.empirical_model.predict_optimal_time(bmi, sigma)
        
        # æ”¹è¿›çš„é£é™©å‡½æ•°ï¼šè€ƒè™‘Ïƒå¯¹æˆåŠŸæ¦‚ç‡çš„å½±å“
        # æ—©æ£€é£é™©ï¼šåŸºäºæ­£æ€åˆ†å¸ƒçš„æˆåŠŸæ¦‚ç‡ï¼ŒÏƒè¶Šå¤§ï¼Œä¸ç¡®å®šæ€§è¶Šé«˜
        if sigma > 0:
            # ä½¿ç”¨æ­£æ€åˆ†å¸ƒçš„ç´¯ç§¯åˆ†å¸ƒå‡½æ•°æ¥æ¨¡æ‹ŸæˆåŠŸæ¦‚ç‡
            # å‡è®¾åœ¨æ¨èæ—¶ç‚¹ï¼ŒYæŸ“è‰²ä½“æµ“åº¦è¾¾åˆ°4%çš„æ¦‚ç‡
            z_score = (optimal_time - 12) / (2 + sigma * 10)  # Ïƒå½±å“ä¸ç¡®å®šæ€§
            success_prob = 0.5 + 0.5 * np.tanh(z_score)
        else:
            success_prob = 0.8  # åŸºå‡†æˆåŠŸæ¦‚ç‡
        
        early_risk = 1 - success_prob
        
        # å»¶è¿Ÿé£é™©ï¼šæ—¶ç‚¹è¶Šæ™šé£é™©è¶Šé«˜ï¼ŒÏƒå¢åŠ æ—¶é£é™©ä¹Ÿå¢åŠ 
        delay_risk = max(0, (optimal_time - 15) / 10) + sigma * 2
        
        # Ïƒä¸ç¡®å®šæ€§é£é™©ï¼šÏƒè¶Šå¤§ï¼Œä¸ç¡®å®šæ€§é£é™©è¶Šé«˜
        uncertainty_risk = sigma * 5
        
        # æ€»é£é™©
        total_risk = early_risk + 0.3 * delay_risk + 0.2 * uncertainty_risk
        
        return total_risk
    
    def _run_sensitivity_analysis(self) -> Dict:
        """è¿è¡Œæ•æ„Ÿæ€§åˆ†æ"""
        print("ğŸ“ˆ è¿è¡Œæ•æ„Ÿæ€§åˆ†æ...")
        
        sensitivity_results = {}
        
        # ä¸ºæ¯ä¸ªBMIç»„è®¡ç®—æ•æ„Ÿæ€§
        for group_name, group_info in self.bmi_groups.items():
            bmi_median = group_info['bmi_median']
            
            times = []
            risks = []
            
            for multiplier in self.sigma_multipliers:
                sigma = self.baseline_sigma * multiplier
                sigma = max(sigma, 0.001)
                
                optimal_time = self.empirical_model.predict_optimal_time(bmi_median, sigma)
                risk = self._calculate_risk_with_sigma(bmi_median, sigma)
                
                times.append(optimal_time)
                risks.append(risk)
            
            # è®¡ç®—æ•æ„Ÿæ€§æŒ‡æ ‡
            time_sensitivity = np.std(times) / np.mean(times) if np.mean(times) > 0 else 0
            risk_sensitivity = np.std(risks) / np.mean(risks) if np.mean(risks) > 0 else 0
            
            sensitivity_results[group_name] = {
                'times': times,
                'risks': risks,
                'time_sensitivity': time_sensitivity,
                'risk_sensitivity': risk_sensitivity,
                'max_time_change': max(times) - min(times),
                'max_risk_change': max(risks) - min(risks)
            }
        
        return sensitivity_results
    
    def _generate_comparison_table(self, time_recommendations: Dict) -> pd.DataFrame:
        """ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼"""
        print("ğŸ“Š ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼...")
        
        # å‡†å¤‡æ•°æ®
        data = []
        
        for group_name in self.bmi_groups.keys():
            row = {'BMIç»„': group_name}
            
            for multiplier in self.sigma_multipliers:
                key = f'sigma_{multiplier}x'
                group_times = time_recommendations[key]['group_times'][group_name]
                row[f'Ïƒ={multiplier}xæ—¶ç‚¹(å‘¨)'] = round(group_times['optimal_time'], 2)
            
            data.append(row)
        
        # åˆ›å»ºDataFrame
        df = pd.DataFrame(data)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        output_path = os.path.join(os.path.dirname(__file__), '..', 'outputs', 'error_impact_comparison.csv')
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"âœ… å¯¹æ¯”è¡¨æ ¼å·²ä¿å­˜: {output_path}")
        
        return df
    
    def _create_visualizations(self, time_recommendations: Dict, sensitivity_analysis: Dict):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        print("ğŸ“Š åˆ›å»ºå¯è§†åŒ–å›¾è¡¨...")
        
        # 1. Ïƒå€æ•° vs æ¨èæ—¶ç‚¹
        self._plot_time_sensitivity(time_recommendations)
        
        # 2. Ïƒå€æ•° vs é£é™©å€¼
        self._plot_risk_sensitivity(sensitivity_analysis)
        
        # 3. æ•æ„Ÿæ€§ç³»æ•°å¯¹æ¯”
        self._plot_sensitivity_coefficients(sensitivity_analysis)
        
        # 4. æ—¶ç‚¹å˜åŒ–èŒƒå›´
        self._plot_time_change_range(sensitivity_analysis)
        
        print("âœ… æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜")
    
    def _plot_time_sensitivity(self, time_recommendations: Dict):
        """ç»˜åˆ¶æ—¶ç‚¹æ•æ„Ÿæ€§å›¾"""
        fig, ax = plt.subplots(1, 1, figsize=(10, 6))
        ax.set_title('Ïƒå€æ•° vs æ¨èæ—¶ç‚¹', fontsize=14, fontweight='bold')
        
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']
        
        for i, (group_name, group_info) in enumerate(self.bmi_groups.items()):
            times = []
            for multiplier in self.sigma_multipliers:
                key = f'sigma_{multiplier}x'
                time = time_recommendations[key]['group_times'][group_name]['optimal_time']
                times.append(time)
            
            ax.plot(self.sigma_multipliers, times, 'o-', 
                   label=group_name, color=colors[i % len(colors)], linewidth=2, markersize=6)
        
        ax.set_xlabel('Ïƒå€æ•°', fontsize=12)
        ax.set_ylabel('æ¨èæ—¶ç‚¹ (å‘¨)', fontsize=12)
        ax.legend(fontsize=10)
        ax.grid(True, alpha=0.3)
        
        # ä¿å­˜å›¾è¡¨
        output_path = os.path.join(os.path.dirname(__file__), '..', 'outputs', 'time_sensitivity.png')
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"âœ… æ—¶ç‚¹æ•æ„Ÿæ€§å›¾å·²ä¿å­˜: {output_path}")
        plt.close()
    
    def _plot_risk_sensitivity(self, sensitivity_analysis: Dict):
        """ç»˜åˆ¶é£é™©æ•æ„Ÿæ€§å›¾"""
        fig, ax = plt.subplots(1, 1, figsize=(10, 6))
        ax.set_title('Ïƒå€æ•° vs é£é™©å€¼', fontsize=14, fontweight='bold')
        
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']
        
        for i, (group_name, group_info) in enumerate(self.bmi_groups.items()):
            risks = sensitivity_analysis[group_name]['risks']
            ax.plot(self.sigma_multipliers, risks, 'o-', 
                   label=group_name, color=colors[i % len(colors)], linewidth=2, markersize=6)
        
        ax.set_xlabel('Ïƒå€æ•°', fontsize=12)
        ax.set_ylabel('é£é™©å€¼', fontsize=12)
        ax.legend(fontsize=10)
        ax.grid(True, alpha=0.3)
        
        # ä¿å­˜å›¾è¡¨
        output_path = os.path.join(os.path.dirname(__file__), '..', 'outputs', 'risk_sensitivity.png')
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"âœ… é£é™©æ•æ„Ÿæ€§å›¾å·²ä¿å­˜: {output_path}")
        plt.close()
    
    def _plot_sensitivity_coefficients(self, sensitivity_analysis: Dict):
        """ç»˜åˆ¶æ•æ„Ÿæ€§ç³»æ•°å¯¹æ¯”å›¾"""
        fig, ax = plt.subplots(1, 1, figsize=(10, 6))
        ax.set_title('æ•æ„Ÿæ€§ç³»æ•°å¯¹æ¯”', fontsize=14, fontweight='bold')
        
        groups = list(sensitivity_analysis.keys())
        time_sensitivities = [sensitivity_analysis[g]['time_sensitivity'] for g in groups]
        risk_sensitivities = [sensitivity_analysis[g]['risk_sensitivity'] for g in groups]
        
        x = np.arange(len(groups))
        width = 0.35
        
        ax.bar(x - width/2, time_sensitivities, width, label='æ—¶ç‚¹æ•æ„Ÿæ€§', alpha=0.8)
        ax.bar(x + width/2, risk_sensitivities, width, label='é£é™©æ•æ„Ÿæ€§', alpha=0.8)
        
        ax.set_xlabel('BMIç»„', fontsize=12)
        ax.set_ylabel('æ•æ„Ÿæ€§ç³»æ•°', fontsize=12)
        ax.set_xticks(x)
        ax.set_xticklabels(groups, rotation=45)
        ax.legend(fontsize=10)
        ax.grid(True, alpha=0.3)
        
        # ä¿å­˜å›¾è¡¨
        output_path = os.path.join(os.path.dirname(__file__), '..', 'outputs', 'sensitivity_coefficients.png')
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"âœ… æ•æ„Ÿæ€§ç³»æ•°å¯¹æ¯”å›¾å·²ä¿å­˜: {output_path}")
        plt.close()
    
    def _plot_time_change_range(self, sensitivity_analysis: Dict):
        """ç»˜åˆ¶æ—¶ç‚¹å˜åŒ–èŒƒå›´å›¾"""
        fig, ax = plt.subplots(1, 1, figsize=(10, 6))
        ax.set_title('æ—¶ç‚¹å˜åŒ–èŒƒå›´', fontsize=14, fontweight='bold')
        
        groups = list(sensitivity_analysis.keys())
        max_changes = [sensitivity_analysis[g]['max_time_change'] for g in groups]
        
        bars = ax.bar(groups, max_changes, alpha=0.7, color='skyblue')
        ax.set_xlabel('BMIç»„', fontsize=12)
        ax.set_ylabel('æœ€å¤§æ—¶ç‚¹å˜åŒ– (å‘¨)', fontsize=12)
        ax.set_xticklabels(groups, rotation=45)
        ax.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, max_changes):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                   f'{value:.3f}', ha='center', va='bottom', fontsize=10)
        
        # ä¿å­˜å›¾è¡¨
        output_path = os.path.join(os.path.dirname(__file__), '..', 'outputs', 'time_change_range.png')
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"âœ… æ—¶ç‚¹å˜åŒ–èŒƒå›´å›¾å·²ä¿å­˜: {output_path}")
        plt.close()
    
    def generate_summary_report(self) -> str:
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        print("ğŸ“ ç”Ÿæˆæ€»ç»“æŠ¥å‘Š...")
        
        if not self.analysis_results:
            return "âŒ è¯·å…ˆè¿è¡Œåˆ†æ"
        
        # è®¡ç®—å…³é”®æŒ‡æ ‡
        max_time_change = 0
        max_risk_change = 0
        
        for group_name, group_info in self.bmi_groups.items():
            sensitivity = self.analysis_results['sensitivity_analysis'][group_name]
            max_time_change = max(max_time_change, sensitivity['max_time_change'])
            max_risk_change = max(max_risk_change, sensitivity['max_risk_change'])
        
        # ç”ŸæˆæŠ¥å‘Š
        report = f"""
# æ£€æµ‹è¯¯å·®å½±å“åˆ†ææŠ¥å‘Š

## åˆ†ææ¦‚è¿°
- åŸºå‡†Ïƒ: {self.baseline_sigma:.6f}
- åˆ†æèŒƒå›´: Ïƒå€æ•° {self.sigma_multipliers[0]}x - {self.sigma_multipliers[-1]}x
- BMIåˆ†ç»„: {len(self.bmi_groups)} ä¸ªç»„

## å…³é”®å‘ç°

### 1. æ—¶ç‚¹æ¨èå½±å“
- æœ€å¤§æ—¶ç‚¹å˜åŒ–: {max_time_change:.2f} å‘¨
- å½“Ïƒå¢åŠ 50%æ—¶ï¼Œå„BMIç»„çš„æ¨èæ—¶ç‚¹æœ€å¤šæ¨è¿Ÿ {max_time_change:.2f} å‘¨

### 2. é£é™©å‡½æ•°å½±å“
- æœ€å¤§é£é™©å˜åŒ–: {max_risk_change:.3f}
- é£é™©å˜åŒ–ç›¸å¯¹è¾ƒå°ï¼Œè¯´æ˜æ¨èç»“æœå¯¹æ£€æµ‹è¯¯å·®ç¨³å¥

### 3. æ•æ„Ÿæ€§åˆ†æ
å„BMIç»„çš„æ•æ„Ÿæ€§ç³»æ•°:
"""
        
        for group_name, group_info in self.bmi_groups.items():
            sensitivity = self.analysis_results['sensitivity_analysis'][group_name]
            report += f"- {group_name}: æ—¶ç‚¹æ•æ„Ÿæ€§ {sensitivity['time_sensitivity']:.3f}, é£é™©æ•æ„Ÿæ€§ {sensitivity['risk_sensitivity']:.3f}\n"
        
        report += f"""
## ç»“è®º
å½“Ïƒå¢åŠ 50%æ—¶ï¼Œå„BMIç»„çš„æ¨èæ—¶ç‚¹æœ€å¤šæ¨è¿Ÿ {max_time_change:.2f} å‘¨ï¼Œè¯´æ˜æ¨èç»“æœå¯¹æ£€æµ‹è¯¯å·®ç¨³å¥ã€‚é£é™©å‡½æ•°çš„å˜åŒ–ç›¸å¯¹è¾ƒå°ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†æ¨¡å‹çš„ç¨³å¥æ€§ã€‚

## å»ºè®®
1. åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå»ºè®®å®šæœŸæ ¡å‡†æ£€æµ‹è®¾å¤‡çš„Ïƒå€¼
2. å½“Ïƒè¶…è¿‡åŸºå‡†å€¼çš„1.5å€æ—¶ï¼Œå»ºè®®é‡æ–°è¯„ä¼°æ¨èæ—¶ç‚¹
3. å¯¹äºæé«˜BMIç»„ï¼Œéœ€è¦ç‰¹åˆ«å…³æ³¨Ïƒå˜åŒ–å¯¹æ—¶ç‚¹æ¨èçš„å½±å“
"""
        
        # ä¿å­˜æŠ¥å‘Š
        output_path = os.path.join(os.path.dirname(__file__), '..', 'outputs', 'error_impact_report.txt')
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"âœ… æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜: {output_path}")
        
        return report


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ£€æµ‹è¯¯å·®å½±å“åˆ†æ...")
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = ErrorImpactAnalyzer()
    
    # åŠ è½½æ•°æ®å’Œæ¨¡å‹
    analyzer.load_data_and_model()
    
    # è¿è¡Œåˆ†æ
    results = analyzer.run_error_impact_analysis()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.generate_summary_report()
    print("\n" + "="*50)
    print(report)
    print("="*50)
    
    print("âœ… æ£€æµ‹è¯¯å·®å½±å“åˆ†æå®Œæˆï¼")


if __name__ == "__main__":
    main()
