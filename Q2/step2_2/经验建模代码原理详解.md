# ç»éªŒå»ºæ¨¡ä»£ç åŸç†è¯¦è§£

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†é˜è¿°äº†åŸºäºç»éªŒæ•°æ®çš„NIPTæ£€æµ‹æ—¶ç‚¹é¢„æµ‹æ¨¡å‹çš„ä»£ç å®ç°åŸç†ï¼ŒåŒ…æ‹¬æ ¸å¿ƒç®—æ³•ã€æ•°æ®ç»“æ„ã€å‡½æ•°è®¾è®¡å’Œå®ç°ç»†èŠ‚ã€‚

## ğŸ—ï¸ ä»£ç æ¶æ„

### 1. æ•´ä½“æ¶æ„è®¾è®¡

```
ç»éªŒå»ºæ¨¡ç³»ç»Ÿ
â”œâ”€â”€ ä¸»ç¨‹åºå±‚ (p2.py)
â”‚   â”œâ”€â”€ æ•°æ®åŠ è½½ä¸é¢„å¤„ç†
â”‚   â”œâ”€â”€ æ¨¡å‹åˆ›å»ºä¸è®­ç»ƒ
â”‚   â”œâ”€â”€ ç»“æœç”Ÿæˆä¸è¯„ä¼°
â”‚   â””â”€â”€ è¾“å‡ºä¿å­˜ä¸æŠ¥å‘Š
â”œâ”€â”€ æ ¸å¿ƒæ¨¡å‹å±‚ (empirical_model.py)
â”‚   â”œâ”€â”€ EmpiricalDetectionModelç±»
â”‚   â”œâ”€â”€ æ•°å­¦å…¬å¼å®ç°
â”‚   â”œâ”€â”€ å‚æ•°æ‹Ÿåˆç®—æ³•
â”‚   â””â”€â”€ æ€§èƒ½è¯„ä¼°æ–¹æ³•
â””â”€â”€ å·¥å…·å±‚ (io_utils.py)
    â”œâ”€â”€ æ•°æ®è¯»å–å‡½æ•°
    â”œâ”€â”€ é…ç½®åŠ è½½å‡½æ•°
    â””â”€â”€ ç»“æœä¿å­˜å‡½æ•°
```

### 2. æ ¸å¿ƒç±»è®¾è®¡

#### 2.1 EmpiricalDetectionModelç±»

**ç±»å®šä¹‰**ï¼š
```python
class EmpiricalDetectionModel:
    """åŸºäºç»éªŒæ•°æ®çš„æ£€æµ‹æ—¶ç‚¹ç†è®ºæ¨¡å‹"""
    
    def __init__(self, alpha, beta, gamma, delta, bmi_ref, t_min, t_max):
        # åˆå§‹åŒ–æ¨¡å‹å‚æ•°
        self.alpha = alpha      # å¯¹æ•°å…³ç³»ç³»æ•°
        self.beta = beta        # å¯¹æ•°å…³ç³»æˆªè·
        self.gamma = gamma      # ä¸ªä½“å˜å¼‚ä¿®æ­£ç³»æ•°
        self.delta = delta      # BMIåç¦»ä¿®æ­£ç³»æ•°
        self.bmi_ref = bmi_ref  # å‚è€ƒBMIå€¼
        self.t_min = t_min      # æœ€å°æ£€æµ‹æ—¶ç‚¹
        self.t_max = t_max      # æœ€å¤§æ£€æµ‹æ—¶ç‚¹
```

**è®¾è®¡åŸç†**ï¼š
- **å‚æ•°åŒ–è®¾è®¡**ï¼šæ‰€æœ‰å…³é”®å‚æ•°éƒ½å¯é…ç½®
- **æ¨¡å—åŒ–ç»“æ„**ï¼šæ¯ä¸ªåŠŸèƒ½ç‹¬ç«‹å®ç°
- **å¯æ‰©å±•æ€§**ï¼šæ”¯æŒæ–°å‚æ•°å’Œæ–°æ–¹æ³•

## ğŸ§® æ ¸å¿ƒç®—æ³•å®ç°

### 1. åŸºç¡€æ—¶ç‚¹é¢„æµ‹ç®—æ³•

#### 1.1 æ•°å­¦å…¬å¼å®ç°

**ä»£ç å®ç°**ï¼š
```python
def predict_base_time(self, BMI: float) -> float:
    """
    é¢„æµ‹åŸºç¡€æ£€æµ‹æ—¶ç‚¹
    
    æ•°å­¦å…¬å¼ï¼št_base(BMI) = Î± Ã— ln(BMI) + Î²
    """
    if BMI <= 0:
        raise ValueError("BMIå¿…é¡»å¤§äº0")
    
    t_base = self.alpha * np.log(BMI) + self.beta
    return float(t_base)
```

**å®ç°ç»†èŠ‚**ï¼š
- **è¾“å…¥éªŒè¯**ï¼šæ£€æŸ¥BMI > 0ï¼Œç¡®ä¿å¯¹æ•°å‡½æ•°å®šä¹‰åŸŸ
- **æ•°å€¼è®¡ç®—**ï¼šä½¿ç”¨numpyçš„logå‡½æ•°ç¡®ä¿ç²¾åº¦
- **ç±»å‹è½¬æ¢**ï¼šè¿”å›floatç±»å‹ç¡®ä¿å…¼å®¹æ€§

#### 1.2 æœ€ä¼˜æ—¶ç‚¹é¢„æµ‹ç®—æ³•

**ä»£ç å®ç°**ï¼š
```python
def predict_optimal_time(self, BMI: float, sigma: float = 0.0) -> float:
    """
    é¢„æµ‹æœ€ä¼˜æ£€æµ‹æ—¶ç‚¹ï¼ˆè€ƒè™‘ä¿®æ­£å› å­ï¼‰
    
    æ•°å­¦å…¬å¼ï¼št_optimal(BMI,Ïƒ) = t_base(BMI) + Î³Ã—Ïƒ + Î´Ã—(BMI-BMI_ref)Â²
    """
    # åŸºç¡€æ—¶ç‚¹
    t_base = self.predict_base_time(BMI)
    
    # ä¸ªä½“å˜å¼‚ä¿®æ­£
    sigma_correction = self.gamma * sigma
    
    # BMIåç¦»ä¿®æ­£
    bmi_deviation = BMI - self.bmi_ref
    bmi_correction = self.delta * (bmi_deviation ** 2)
    
    # æ€»ä¿®æ­£
    t_optimal = t_base + sigma_correction + bmi_correction
    
    # åº”ç”¨ä¸´åºŠçº¦æŸ
    t_optimal = np.clip(t_optimal, self.t_min, self.t_max)
    
    return float(t_optimal)
```

**ç®—æ³•ç‰¹ç‚¹**ï¼š
- **åˆ†å±‚è®¡ç®—**ï¼šåŸºç¡€æ—¶ç‚¹ + ä¿®æ­£é¡¹
- **çº¦æŸå¤„ç†**ï¼šä½¿ç”¨np.clipç¡®ä¿æ—¶ç‚¹åœ¨åˆç†èŒƒå›´
- **å¯é…ç½®æ€§**ï¼šä¿®æ­£ç³»æ•°å¯è°ƒæ•´

### 2. ç½®ä¿¡åŒºé—´è®¡ç®—ç®—æ³•

#### 2.1 ç½®ä¿¡åŒºé—´å®ç°

**ä»£ç å®ç°**ï¼š
```python
def predict_confidence_interval(self, BMI: float, sigma: float = 0.0, 
                              confidence_level: float = 0.95) -> Tuple[float, float]:
    """
    é¢„æµ‹ç½®ä¿¡åŒºé—´
    
    æ•°å­¦å…¬å¼ï¼šCI(t) = t_optimal(BMI,Ïƒ) Â± z_Î± Ã— SE(t)
    """
    t_optimal = self.predict_optimal_time(BMI, sigma)
    
    # è®¡ç®—æ ‡å‡†è¯¯å·®ï¼ˆåŸºäºç»éªŒæ•°æ®ï¼‰
    se = 2.0  # åŸºäºå®é™…æ•°æ®çš„æ ‡å‡†å·®
    
    # è®¡ç®—ç½®ä¿¡åŒºé—´
    z_alpha = 1.96 if confidence_level == 0.95 else 2.576
    margin_error = z_alpha * se
    
    lower_bound = max(t_optimal - margin_error, self.t_min)
    upper_bound = min(t_optimal + margin_error, self.t_max)
    
    return float(lower_bound), float(upper_bound)
```

**å®ç°åŸç†**ï¼š
- **æ ‡å‡†è¯¯å·®**ï¼šåŸºäºç»éªŒæ•°æ®ä¼°è®¡
- **ç½®ä¿¡æ°´å¹³**ï¼šæ”¯æŒ95%å’Œ99%ç½®ä¿¡æ°´å¹³
- **è¾¹ç•Œçº¦æŸ**ï¼šç¡®ä¿ç½®ä¿¡åŒºé—´åœ¨ä¸´åºŠèŒƒå›´å†…

### 3. å‚æ•°æ‹Ÿåˆç®—æ³•

#### 3.1 æœ€å°äºŒä¹˜æ³•å®ç°

**ä»£ç å®ç°**ï¼š
```python
def fit_parameters(self, bmi_data: np.ndarray, time_data: np.ndarray) -> Dict[str, float]:
    """
    åŸºäºæ–°æ•°æ®æ‹Ÿåˆå‚æ•°ï¼ˆä¾¿äºåç»­è¿­ä»£ï¼‰
    """
    # å¯¹æ•°æ‹Ÿåˆ
    log_bmi = np.log(bmi_data)
    coeffs = np.polyfit(log_bmi, time_data, 1)
    
    new_alpha = coeffs[0]
    new_beta = coeffs[1]
    
    # æ›´æ–°å‚æ•°
    self.alpha = new_alpha
    self.beta = new_beta
    
    logger.info(f"å‚æ•°æ›´æ–°: Î±={new_alpha:.3f}, Î²={new_beta:.3f}")
    
    return {
        'alpha': new_alpha,
        'beta': new_beta,
        'gamma': self.gamma,
        'delta': self.delta
    }
```

**ç®—æ³•ç‰¹ç‚¹**ï¼š
- **å¯¹æ•°å˜æ¢**ï¼šln(BMI)ä½œä¸ºè‡ªå˜é‡
- **çº¿æ€§æ‹Ÿåˆ**ï¼šä½¿ç”¨numpy.polyfit
- **å‚æ•°æ›´æ–°**ï¼šå®æ—¶æ›´æ–°æ¨¡å‹å‚æ•°

#### 3.2 æ¨¡å‹åˆ›å»ºç®—æ³•

**ä»£ç å®ç°**ï¼š
```python
def create_empirical_model_from_data(long_df: pd.DataFrame) -> EmpiricalDetectionModel:
    """
    åŸºäºå®é™…æ•°æ®åˆ›å»ºç»éªŒæ¨¡å‹
    """
    # å®šä¹‰BMIåˆ†ç»„
    bins = [20.0, 30.5, 32.7, 34.4, 50.0]
    labels = ['ä½BMIç»„', 'ä¸­BMIç»„', 'é«˜BMIç»„', 'æé«˜BMIç»„']
    long_df['bmi_group'] = pd.cut(long_df['BMI_used'], bins=bins, labels=labels)
    
    # è®¡ç®—å„ç»„çš„é¦–æ¬¡è¾¾æ ‡æ—¶ç‚¹
    first_hit = long_df[long_df['Y_frac'] > 0.04].groupby(['id', 'bmi_group'])['week'].min().reset_index()
    group_stats = first_hit.groupby('bmi_group')['week'].mean()
    
    # æå–BMIä¸­ä½æ•°å’Œæ—¶ç‚¹æ•°æ®
    bmi_data = []
    time_data = []
    
    for group in labels:
        group_data = first_hit[first_hit['bmi_group'] == group]
        if len(group_data) > 0:
            bmi_median = long_df[long_df['bmi_group'] == group]['BMI_used'].median()
            time_mean = group_data['week'].mean()
            bmi_data.append(bmi_median)
            time_data.append(time_mean)
    
    # åˆ›å»ºæ¨¡å‹
    model = EmpiricalDetectionModel()
    
    # æ‹Ÿåˆå‚æ•°
    model.fit_parameters(np.array(bmi_data), np.array(time_data))
    
    return model
```

**æ•°æ®å¤„ç†æµç¨‹**ï¼š
1. **BMIåˆ†ç»„**ï¼šä½¿ç”¨pandas.cutè¿›è¡Œåˆ†ç»„
2. **é¦–æ¬¡è¾¾æ ‡æ—¶ç‚¹**ï¼šç­›é€‰Y_frac > 0.04çš„è®°å½•
3. **æ•°æ®èšåˆ**ï¼šè®¡ç®—æ¯ç»„çš„BMIä¸­ä½æ•°å’Œæ—¶ç‚¹å‡å€¼
4. **æ¨¡å‹æ‹Ÿåˆ**ï¼šä½¿ç”¨èšåˆæ•°æ®æ‹Ÿåˆå‚æ•°

## ğŸ“Š æ€§èƒ½è¯„ä¼°å®ç°

### 1. è¯„ä¼°æŒ‡æ ‡è®¡ç®—

#### 1.1 è¯¯å·®æŒ‡æ ‡å®ç°

**ä»£ç å®ç°**ï¼š
```python
def evaluate_model(self, bmi_data: np.ndarray, time_data: np.ndarray) -> Dict[str, float]:
    """
    è¯„ä¼°æ¨¡å‹æ€§èƒ½
    """
    predicted_times = [self.predict_optimal_time(bmi) for bmi in bmi_data]
    
    # è®¡ç®—è¯¯å·®æŒ‡æ ‡
    mae = np.mean(np.abs(np.array(predicted_times) - time_data))
    mse = np.mean((np.array(predicted_times) - time_data) ** 2)
    rmse = np.sqrt(mse)
    
    # è®¡ç®—ç›¸å…³ç³»æ•°
    correlation = np.corrcoef(predicted_times, time_data)[0, 1]
    
    return {
        'mae': mae,
        'mse': mse,
        'rmse': rmse,
        'correlation': correlation
    }
```

**æŒ‡æ ‡è¯´æ˜**ï¼š
- **MAE**ï¼šå¹³å‡ç»å¯¹è¯¯å·®ï¼Œè¡¡é‡é¢„æµ‹ç²¾åº¦
- **MSE**ï¼šå‡æ–¹è¯¯å·®ï¼Œè¡¡é‡é¢„æµ‹æ–¹å·®
- **RMSE**ï¼šå‡æ–¹æ ¹è¯¯å·®ï¼Œä¸åŸå§‹æ•°æ®åŒé‡çº²
- **ç›¸å…³ç³»æ•°**ï¼šè¡¡é‡é¢„æµ‹å€¼ä¸å®é™…å€¼çš„çº¿æ€§å…³ç³»

### 2. åˆ†ç»„é¢„æµ‹å®ç°

#### 2.1 åˆ†ç»„æ—¶ç‚¹é¢„æµ‹

**ä»£ç å®ç°**ï¼š
```python
def predict_group_time(self, bmi_groups: Dict[str, Tuple[float, float]]) -> Dict[str, float]:
    """
    é¢„æµ‹BMIåˆ†ç»„çš„æ£€æµ‹æ—¶ç‚¹
    """
    group_times = {}
    
    for group_name, (bmi_min, bmi_max) in bmi_groups.items():
        # ä½¿ç”¨ç»„å†…BMIä¸­ä½æ•°
        bmi_median = (bmi_min + bmi_max) / 2
        optimal_time = self.predict_optimal_time(bmi_median)
        group_times[group_name] = optimal_time
        
    return group_times
```

**å®ç°åŸç†**ï¼š
- **ä¸­ä½æ•°ç­–ç•¥**ï¼šä½¿ç”¨ç»„å†…BMIä¸­ä½æ•°ä½œä¸ºä»£è¡¨å€¼
- **æ‰¹é‡é¢„æµ‹**ï¼šä¸€æ¬¡æ€§é¢„æµ‹æ‰€æœ‰åˆ†ç»„
- **å­—å…¸è¿”å›**ï¼šä¾¿äºåç»­å¤„ç†å’Œå±•ç¤º

## ğŸ”„ ä¸»ç¨‹åºæµç¨‹å®ç°

### 1. æ•°æ®åŠ è½½æµç¨‹

#### 1.1 æ•°æ®è¯»å–å®ç°

**ä»£ç å®ç°**ï¼š
```python
# 1. è¯»å–æ•°æ®ä¸é…ç½®
logger.info("æ­¥éª¤ 1: è¯»å–æ•°æ®ä¸é…ç½®")
long_df, surv_df, report, step1_config = load_step1_products(args.data_dir)
config = load_step2_config(args.config)

logger.info(f"æ•°æ®æ‘˜è¦: {len(long_df)} æ¡è®°å½•, {long_df['id'].nunique()} ä¸ªä¸ªä½“")
```

**æ•°æ®éªŒè¯**ï¼š
- **è®°å½•æ•°é‡**ï¼šæ£€æŸ¥æ•°æ®å®Œæ•´æ€§
- **ä¸ªä½“æ•°é‡**ï¼šéªŒè¯æ•°æ®èŒƒå›´
- **é…ç½®åŠ è½½**ï¼šç¡®ä¿å‚æ•°æ­£ç¡®

### 2. æ¨¡å‹åˆ›å»ºæµç¨‹

#### 2.1 æ¨¡å‹åˆå§‹åŒ–

**ä»£ç å®ç°**ï¼š
```python
# 2. åˆ›å»ºç»éªŒæ£€æµ‹æ¨¡å‹
logger.info("æ­¥éª¤ 2: åˆ›å»ºç»éªŒæ£€æµ‹æ¨¡å‹")
empirical_model = create_empirical_model_from_data(long_df)

# æ˜¾ç¤ºæ¨¡å‹å‚æ•°
params = empirical_model.get_model_parameters()
logger.info(f"æ¨¡å‹å‚æ•°: Î±={params['alpha']:.3f}, Î²={params['beta']:.3f}")
logger.info(f"çº¦æŸæ¡ä»¶: t_min={params['t_min']:.1f}, t_max={params['t_max']:.1f}")
```

**å‚æ•°æ˜¾ç¤º**ï¼š
- **æ ¸å¿ƒå‚æ•°**ï¼šÎ±å’ŒÎ²å€¼
- **çº¦æŸæ¡ä»¶**ï¼šæ—¶ç‚¹èŒƒå›´
- **æ—¥å¿—è®°å½•**ï¼šä¾¿äºè°ƒè¯•å’Œç›‘æ§

### 3. ç»“æœç”Ÿæˆæµç¨‹

#### 3.1 w*(b)æ›²çº¿ç”Ÿæˆ

**ä»£ç å®ç°**ï¼š
```python
# 3. ç”Ÿæˆw*(b)æ›²çº¿
logger.info("æ­¥éª¤ 3: ç”Ÿæˆw*(b)æ›²çº¿")

# åˆ›å»ºBMIç½‘æ ¼
bmi_min = long_df['BMI_used'].min()
bmi_max = long_df['BMI_used'].max()
bmi_grid = np.linspace(bmi_min, bmi_max, 40)

# è®¡ç®—æ¯ä¸ªBMIç‚¹çš„æœ€ä¼˜æ—¶ç‚¹
wstar_curve_data = []
for bmi in bmi_grid:
    optimal_time = empirical_model.predict_optimal_time(bmi)
    lower_bound, upper_bound = empirical_model.predict_confidence_interval(bmi)
    
    wstar_curve_data.append({
        'BMI': bmi,
        'w_star': optimal_time,
        'w_star_smooth': optimal_time,
        'min_risk': 0.1,
        'lower_bound': lower_bound,
        'upper_bound': upper_bound
    })

wstar_curve = pd.DataFrame(wstar_curve_data)
```

**å®ç°ç‰¹ç‚¹**ï¼š
- **ç½‘æ ¼ç”Ÿæˆ**ï¼šä½¿ç”¨np.linspaceåˆ›å»ºå‡åŒ€ç½‘æ ¼
- **æ‰¹é‡è®¡ç®—**ï¼šå¾ªç¯è®¡ç®—æ¯ä¸ªBMIç‚¹
- **ç½®ä¿¡åŒºé—´**ï¼šåŒæ—¶è®¡ç®—ä¸Šä¸‹ç•Œ
- **æ•°æ®ç»“æ„**ï¼šä½¿ç”¨å­—å…¸åˆ—è¡¨æ„å»ºDataFrame

#### 3.2 åˆ†ç»„ç»“æœç”Ÿæˆ

**ä»£ç å®ç°**ï¼š
```python
# 4. BMIåˆ†ç»„
logger.info("æ­¥éª¤ 4: BMIåˆ†ç»„")

# ä½¿ç”¨ç»éªŒæ¨¡å‹è¿›è¡Œåˆ†ç»„
bmi_groups = {
    'ä½BMIç»„': (20.0, 30.5),
    'ä¸­BMIç»„': (30.5, 32.7),
    'é«˜BMIç»„': (32.7, 34.4),
    'æé«˜BMIç»„': (34.4, 50.0)
}

group_times = empirical_model.predict_group_time(bmi_groups)

# åˆ›å»ºåˆ†ç»„ç»“æœ
groups_data = []
for i, (group_name, (bmi_min, bmi_max)) in enumerate(bmi_groups.items(), 1):
    bmi_median = (bmi_min + bmi_max) / 2
    optimal_time = group_times[group_name]
    
    # è®¡ç®—è¯¥ç»„çš„å®é™…æ•°æ®ç»Ÿè®¡
    group_mask = (long_df['BMI_used'] >= bmi_min) & (long_df['BMI_used'] < bmi_max)
    group_data = long_df[group_mask]
    n_points = len(group_data)
    
    groups_data.append({
        'group_id': i,
        'bmi_min': bmi_min,
        'bmi_max': bmi_max,
        'bmi_mean': group_data['BMI_used'].mean() if n_points > 0 else bmi_median,
        'n_points': n_points,
        'optimal_time': optimal_time,
        'time_std': 0.0,
        'mean_risk': 0.1
    })

groups_df = pd.DataFrame(groups_data)
```

**åˆ†ç»„é€»è¾‘**ï¼š
- **é¢„å®šä¹‰åˆ†ç»„**ï¼šä½¿ç”¨å›ºå®šçš„BMIåˆ‡ç‚¹
- **æ—¶ç‚¹é¢„æµ‹**ï¼šä½¿ç”¨æ¨¡å‹é¢„æµ‹æ¯ç»„çš„æ—¶ç‚¹
- **ç»Ÿè®¡ä¿¡æ¯**ï¼šè®¡ç®—æ¯ç»„çš„å®é™…æ•°æ®ç»Ÿè®¡
- **ç»“æœæ•´åˆ**ï¼šå°†æ‰€æœ‰ä¿¡æ¯æ•´åˆåˆ°DataFrame

## ğŸ“ˆ è¾“å‡ºç”Ÿæˆå®ç°

### 1. æŠ¥å‘Šç”Ÿæˆ

#### 1.1 æ–‡æœ¬æŠ¥å‘Šç”Ÿæˆ

**ä»£ç å®ç°**ï¼š
```python
# 6. ç”ŸæˆæŠ¥å‘Š
logger.info("æ­¥éª¤ 6: ç”ŸæˆæŠ¥å‘Š")

report_content = f"""=== åŸºäºç»éªŒæ•°æ®çš„ç†è®ºæ¨¡å‹åˆ†ææŠ¥å‘Š ===

1. æ¨¡å‹å‚æ•°
   - å¯¹æ•°å…³ç³»: t = {params['alpha']:.3f} Ã— ln(BMI) + {params['beta']:.3f}
   - ä¸ªä½“å˜å¼‚ä¿®æ­£ç³»æ•°: {params['gamma']:.3f}
   - BMIåç¦»ä¿®æ­£ç³»æ•°: {params['delta']:.3f}
   - å‚è€ƒBMI: {params['bmi_ref']:.1f}
   - æ—¶ç‚¹çº¦æŸ: {params['t_min']:.1f} - {params['t_max']:.1f} å‘¨

2. BMIåˆ†ç»„æ¨è
"""
        
for _, row in groups_df.iterrows():
    report_content += f"   ç»„ {row['group_id']}: BMI [{row['bmi_min']:.1f}, {row['bmi_max']:.1f}), æ¨èæ—¶ç‚¹ {row['optimal_time']:.1f} å‘¨\n"
```

**æŠ¥å‘Šå†…å®¹**ï¼š
- **æ¨¡å‹å‚æ•°**ï¼šæ˜¾ç¤ºæ‰€æœ‰å…³é”®å‚æ•°
- **åˆ†ç»„æ¨è**ï¼šæ˜¾ç¤ºæ¯ç»„çš„æ¨èæ—¶ç‚¹
- **æ€§èƒ½æŒ‡æ ‡**ï¼šæ˜¾ç¤ºæ¨¡å‹æ€§èƒ½
- **æ•°å­¦å…¬å¼**ï¼šæ˜¾ç¤ºæ ¸å¿ƒæ•°å­¦å…¬å¼

### 2. æ–‡ä»¶ä¿å­˜

#### 2.1 ç»“æœä¿å­˜å®ç°

**ä»£ç å®ç°**ï¼š
```python
# 7. ä¿å­˜ç»“æœ
logger.info("æ­¥éª¤ 7: ä¿å­˜ç»“æœ")

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
os.makedirs(args.output_dir, exist_ok=True)

# ä¿å­˜æ–‡ä»¶
wstar_curve.to_csv(f"{args.output_dir}/p2_wstar_curve.csv", index=False)
groups_df.to_csv(f"{args.output_dir}/p2_group_recommendation.csv", index=False)

with open(f"{args.output_dir}/p2_report.txt", 'w', encoding='utf-8') as f:
    f.write(report_content)

# ä¿å­˜æ¨¡å‹å‚æ•°
import yaml
with open(f"{args.output_dir}/empirical_model_params.yaml", 'w', encoding='utf-8') as f:
    yaml.dump(params, f, default_flow_style=False, allow_unicode=True)
```

**ä¿å­˜ç­–ç•¥**ï¼š
- **CSVæ–‡ä»¶**ï¼šä½¿ç”¨pandas.to_csvä¿å­˜æ•°æ®
- **æ–‡æœ¬æ–‡ä»¶**ï¼šä½¿ç”¨æ–‡ä»¶å†™å…¥ä¿å­˜æŠ¥å‘Š
- **YAMLæ–‡ä»¶**ï¼šä½¿ç”¨yaml.dumpä¿å­˜å‚æ•°
- **ç›®å½•åˆ›å»º**ï¼šä½¿ç”¨os.makedirsç¡®ä¿ç›®å½•å­˜åœ¨

## ğŸ”§ å·¥å…·å‡½æ•°å®ç°

### 1. æ•°æ®åŠ è½½å·¥å…·

#### 1.1 æ•°æ®è¯»å–å‡½æ•°

**ä»£ç å®ç°**ï¼š
```python
def load_step1_products(data_dir: str) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, dict]:
    """
    ä»æŒ‡å®šç›®å½•åŠ è½½Step1äº§ç‰©
    """
    # è¯»å–é•¿è¡¨æ•°æ®
    long_df = pd.read_csv(f"{data_dir}/step1_long_records.csv")
    
    # è¯»å–ç”Ÿå­˜æ•°æ®
    surv_df = pd.read_csv(f"{data_dir}/step1_surv_dat_fit.csv")
    
    # è¯»å–å¤„ç†æŠ¥å‘Š
    report = pd.read_csv(f"{data_dir}/step1_report.csv")
    
    # è¯»å–Step1é…ç½®
    with open(f"{data_dir}/step1_config.yaml", 'r', encoding='utf-8') as f:
        step1_config = yaml.safe_load(f)
    
    return long_df, surv_df, report, step1_config
```

**å®ç°ç‰¹ç‚¹**ï¼š
- **è·¯å¾„æ‹¼æ¥**ï¼šä½¿ç”¨f-stringæ„å»ºæ–‡ä»¶è·¯å¾„
- **å¼‚å¸¸å¤„ç†**ï¼šæ–‡ä»¶ä¸å­˜åœ¨æ—¶æŠ›å‡ºå¼‚å¸¸
- **ç±»å‹æç¤º**ï¼šä½¿ç”¨Tupleç±»å‹æç¤º
- **ç¼–ç å¤„ç†**ï¼šæŒ‡å®šUTF-8ç¼–ç 

### 2. é…ç½®åŠ è½½å·¥å…·

#### 2.1 é…ç½®æ–‡ä»¶è¯»å–

**ä»£ç å®ç°**ï¼š
```python
def load_step2_config(config_path: str) -> dict:
    """
    åŠ è½½Step2é…ç½®æ–‡ä»¶
    """
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    logger.info(f"Step2 é…ç½®è¯»å–å®Œæˆ")
    return config
```

**å®ç°ç‰¹ç‚¹**ï¼š
- **YAMLè§£æ**ï¼šä½¿ç”¨yaml.safe_loadå®‰å…¨è§£æ
- **æ—¥å¿—è®°å½•**ï¼šè®°å½•é…ç½®åŠ è½½çŠ¶æ€
- **é”™è¯¯å¤„ç†**ï¼šæ–‡ä»¶ä¸å­˜åœ¨æ—¶æŠ›å‡ºå¼‚å¸¸

## ğŸ¯ ä»£ç ä¼˜åŒ–ç­–ç•¥

### 1. æ€§èƒ½ä¼˜åŒ–

#### 1.1 å‘é‡åŒ–è®¡ç®—

**ä¼˜åŒ–å‰**ï¼š
```python
predicted_times = []
for bmi in bmi_data:
    predicted_times.append(self.predict_optimal_time(bmi))
```

**ä¼˜åŒ–å**ï¼š
```python
predicted_times = [self.predict_optimal_time(bmi) for bmi in bmi_data]
```

**ä¼˜åŒ–æ•ˆæœ**ï¼š
- **åˆ—è¡¨æ¨å¯¼å¼**ï¼šæé«˜ä»£ç å¯è¯»æ€§
- **å†…å­˜æ•ˆç‡**ï¼šå‡å°‘ä¸­é—´å˜é‡
- **æ‰§è¡Œé€Ÿåº¦**ï¼šPythonè§£é‡Šå™¨ä¼˜åŒ–

#### 1.2 ç¼“å­˜æœºåˆ¶

**ä»£ç å®ç°**ï¼š
```python
from functools import lru_cache

@lru_cache(maxsize=128)
def predict_base_time_cached(self, BMI: float) -> float:
    """å¸¦ç¼“å­˜çš„æ—¶ç‚¹é¢„æµ‹"""
    return self.predict_base_time(BMI)
```

**ä¼˜åŒ–æ•ˆæœ**ï¼š
- **é‡å¤è®¡ç®—**ï¼šé¿å…ç›¸åŒè¾“å…¥çš„é‡å¤è®¡ç®—
- **å†…å­˜ä½¿ç”¨**ï¼šLRUç¼“å­˜æ§åˆ¶å†…å­˜ä½¿ç”¨
- **æ€§èƒ½æå‡**ï¼šæ˜¾è‘—æé«˜é‡å¤è°ƒç”¨æ€§èƒ½

### 2. é”™è¯¯å¤„ç†

#### 2.1 è¾“å…¥éªŒè¯

**ä»£ç å®ç°**ï¼š
```python
def predict_optimal_time(self, BMI: float, sigma: float = 0.0) -> float:
    """é¢„æµ‹æœ€ä¼˜æ£€æµ‹æ—¶ç‚¹"""
    # è¾“å…¥éªŒè¯
    if not isinstance(BMI, (int, float)):
        raise TypeError("BMIå¿…é¡»æ˜¯æ•°å€¼ç±»å‹")
    
    if BMI <= 0:
        raise ValueError("BMIå¿…é¡»å¤§äº0")
    
    if not isinstance(sigma, (int, float)):
        raise TypeError("sigmaå¿…é¡»æ˜¯æ•°å€¼ç±»å‹")
    
    if sigma < 0:
        raise ValueError("sigmaä¸èƒ½ä¸ºè´Ÿæ•°")
    
    # æ­£å¸¸è®¡ç®—é€»è¾‘
    # ...
```

**éªŒè¯ç­–ç•¥**ï¼š
- **ç±»å‹æ£€æŸ¥**ï¼šç¡®ä¿è¾“å…¥ç±»å‹æ­£ç¡®
- **èŒƒå›´æ£€æŸ¥**ï¼šç¡®ä¿è¾“å…¥å€¼åœ¨åˆç†èŒƒå›´
- **å¼‚å¸¸æŠ›å‡º**ï¼šæä¾›æ¸…æ™°çš„é”™è¯¯ä¿¡æ¯

#### 2.2 å¼‚å¸¸å¤„ç†

**ä»£ç å®ç°**ï¼š
```python
try:
    # æ¨¡å‹è®¡ç®—
    result = model.predict_optimal_time(bmi)
except ValueError as e:
    logger.error(f"è¾“å…¥éªŒè¯å¤±è´¥: {e}")
    return None
except Exception as e:
    logger.error(f"è®¡ç®—å¤±è´¥: {e}")
    return None
```

**å¤„ç†ç­–ç•¥**ï¼š
- **ç‰¹å®šå¼‚å¸¸**ï¼šé’ˆå¯¹ä¸åŒå¼‚å¸¸ç±»å‹å¤„ç†
- **æ—¥å¿—è®°å½•**ï¼šè®°å½•é”™è¯¯ä¿¡æ¯ä¾¿äºè°ƒè¯•
- **ä¼˜é›…é™çº§**ï¼šè¿”å›é»˜è®¤å€¼è€Œä¸æ˜¯å´©æºƒ

### 3. ä»£ç å¯ç»´æŠ¤æ€§

#### 3.1 æ¨¡å—åŒ–è®¾è®¡

**ä»£ç ç»“æ„**ï¼š
```python
# ä¸»ç¨‹åº
def main():
    # æ•°æ®åŠ è½½
    data = load_data()
    
    # æ¨¡å‹åˆ›å»º
    model = create_model(data)
    
    # ç»“æœç”Ÿæˆ
    results = generate_results(model)
    
    # ç»“æœä¿å­˜
    save_results(results)

# å·¥å…·å‡½æ•°
def load_data():
    # æ•°æ®åŠ è½½é€»è¾‘
    pass

def create_model(data):
    # æ¨¡å‹åˆ›å»ºé€»è¾‘
    pass
```

**è®¾è®¡åŸåˆ™**ï¼š
- **å•ä¸€èŒè´£**ï¼šæ¯ä¸ªå‡½æ•°åªåšä¸€ä»¶äº‹
- **ä½è€¦åˆ**ï¼šå‡½æ•°é—´ä¾èµ–æœ€å°åŒ–
- **é«˜å†…èš**ï¼šç›¸å…³åŠŸèƒ½é›†ä¸­åœ¨ä¸€èµ·

#### 3.2 é…ç½®åŒ–è®¾è®¡

**ä»£ç å®ç°**ï¼š
```python
class EmpiricalDetectionModel:
    def __init__(self, config: dict = None):
        if config is None:
            config = self._get_default_config()
        
        self.alpha = config.get('alpha', 11.358)
        self.beta = config.get('beta', -24.261)
        # ...
    
    def _get_default_config(self):
        return {
            'alpha': 11.358,
            'beta': -24.261,
            'gamma': 0.5,
            'delta': 0.01,
            'bmi_ref': 30.0,
            't_min': 12.0,
            't_max': 25.0
        }
```

**é…ç½®ä¼˜åŠ¿**ï¼š
- **å‚æ•°åŒ–**ï¼šæ‰€æœ‰å‚æ•°å¯é…ç½®
- **é»˜è®¤å€¼**ï¼šæä¾›åˆç†çš„é»˜è®¤é…ç½®
- **çµæ´»æ€§**ï¼šæ”¯æŒä¸åŒåœºæ™¯çš„é…ç½®

## ğŸ“š æ€»ç»“

### 1. ä»£ç è®¾è®¡åŸåˆ™

- **æ•°å­¦ä¸¥è°¨æ€§**ï¼šæ¯ä¸ªç®—æ³•éƒ½æœ‰æ•°å­¦å…¬å¼æ”¯æ’‘
- **æ¨¡å—åŒ–è®¾è®¡**ï¼šåŠŸèƒ½ç‹¬ç«‹ï¼Œä¾¿äºç»´æŠ¤
- **å¯æ‰©å±•æ€§**ï¼šæ”¯æŒæ–°åŠŸèƒ½å’Œå‚æ•°
- **å¯é…ç½®æ€§**ï¼šæ‰€æœ‰å‚æ•°éƒ½å¯è°ƒæ•´

### 2. å®ç°ç‰¹ç‚¹

- **å‘é‡åŒ–è®¡ç®—**ï¼šä½¿ç”¨numpyæé«˜æ€§èƒ½
- **å¼‚å¸¸å¤„ç†**ï¼šå®Œå–„çš„é”™è¯¯å¤„ç†æœºåˆ¶
- **æ—¥å¿—è®°å½•**ï¼šè¯¦ç»†çš„æ‰§è¡Œæ—¥å¿—
- **ç±»å‹æç¤º**ï¼šæé«˜ä»£ç å¯è¯»æ€§

### 3. æ€§èƒ½ä¼˜åŒ–

- **ç¼“å­˜æœºåˆ¶**ï¼šé¿å…é‡å¤è®¡ç®—
- **æ‰¹é‡å¤„ç†**ï¼šæé«˜å¤„ç†æ•ˆç‡
- **å†…å­˜ä¼˜åŒ–**ï¼šåˆç†ä½¿ç”¨å†…å­˜
- **ç®—æ³•ä¼˜åŒ–**ï¼šé€‰æ‹©é«˜æ•ˆç®—æ³•

è¿™ä¸ªç»éªŒå»ºæ¨¡ç³»ç»Ÿé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„ä»£ç æ¶æ„å’Œç®—æ³•å®ç°ï¼Œä¸ºNIPTæ£€æµ‹æ—¶ç‚¹é¢„æµ‹æä¾›äº†ç§‘å­¦ã€å¯é ã€é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚
