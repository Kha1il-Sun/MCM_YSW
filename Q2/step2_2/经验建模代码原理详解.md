# 经验建模代码原理详解

## 📋 概述

本文档详细阐述了基于经验数据的NIPT检测时点预测模型的代码实现原理，包括核心算法、数据结构、函数设计和实现细节。

## 🏗️ 代码架构

### 1. 整体架构设计

```
经验建模系统
├── 主程序层 (p2.py)
│   ├── 数据加载与预处理
│   ├── 模型创建与训练
│   ├── 结果生成与评估
│   └── 输出保存与报告
├── 核心模型层 (empirical_model.py)
│   ├── EmpiricalDetectionModel类
│   ├── 数学公式实现
│   ├── 参数拟合算法
│   └── 性能评估方法
└── 工具层 (io_utils.py)
    ├── 数据读取函数
    ├── 配置加载函数
    └── 结果保存函数
```

### 2. 核心类设计

#### 2.1 EmpiricalDetectionModel类

**类定义**：
```python
class EmpiricalDetectionModel:
    """基于经验数据的检测时点理论模型"""
    
    def __init__(self, alpha, beta, gamma, delta, bmi_ref, t_min, t_max):
        # 初始化模型参数
        self.alpha = alpha      # 对数关系系数
        self.beta = beta        # 对数关系截距
        self.gamma = gamma      # 个体变异修正系数
        self.delta = delta      # BMI偏离修正系数
        self.bmi_ref = bmi_ref  # 参考BMI值
        self.t_min = t_min      # 最小检测时点
        self.t_max = t_max      # 最大检测时点
```

**设计原理**：
- **参数化设计**：所有关键参数都可配置
- **模块化结构**：每个功能独立实现
- **可扩展性**：支持新参数和新方法

## 🧮 核心算法实现

### 1. 基础时点预测算法

#### 1.1 数学公式实现

**代码实现**：
```python
def predict_base_time(self, BMI: float) -> float:
    """
    预测基础检测时点
    
    数学公式：t_base(BMI) = α × ln(BMI) + β
    """
    if BMI <= 0:
        raise ValueError("BMI必须大于0")
    
    t_base = self.alpha * np.log(BMI) + self.beta
    return float(t_base)
```

**实现细节**：
- **输入验证**：检查BMI > 0，确保对数函数定义域
- **数值计算**：使用numpy的log函数确保精度
- **类型转换**：返回float类型确保兼容性

#### 1.2 最优时点预测算法

**代码实现**：
```python
def predict_optimal_time(self, BMI: float, sigma: float = 0.0) -> float:
    """
    预测最优检测时点（考虑修正因子）
    
    数学公式：t_optimal(BMI,σ) = t_base(BMI) + γ×σ + δ×(BMI-BMI_ref)²
    """
    # 基础时点
    t_base = self.predict_base_time(BMI)
    
    # 个体变异修正
    sigma_correction = self.gamma * sigma
    
    # BMI偏离修正
    bmi_deviation = BMI - self.bmi_ref
    bmi_correction = self.delta * (bmi_deviation ** 2)
    
    # 总修正
    t_optimal = t_base + sigma_correction + bmi_correction
    
    # 应用临床约束
    t_optimal = np.clip(t_optimal, self.t_min, self.t_max)
    
    return float(t_optimal)
```

**算法特点**：
- **分层计算**：基础时点 + 修正项
- **约束处理**：使用np.clip确保时点在合理范围
- **可配置性**：修正系数可调整

### 2. 置信区间计算算法

#### 2.1 置信区间实现

**代码实现**：
```python
def predict_confidence_interval(self, BMI: float, sigma: float = 0.0, 
                              confidence_level: float = 0.95) -> Tuple[float, float]:
    """
    预测置信区间
    
    数学公式：CI(t) = t_optimal(BMI,σ) ± z_α × SE(t)
    """
    t_optimal = self.predict_optimal_time(BMI, sigma)
    
    # 计算标准误差（基于经验数据）
    se = 2.0  # 基于实际数据的标准差
    
    # 计算置信区间
    z_alpha = 1.96 if confidence_level == 0.95 else 2.576
    margin_error = z_alpha * se
    
    lower_bound = max(t_optimal - margin_error, self.t_min)
    upper_bound = min(t_optimal + margin_error, self.t_max)
    
    return float(lower_bound), float(upper_bound)
```

**实现原理**：
- **标准误差**：基于经验数据估计
- **置信水平**：支持95%和99%置信水平
- **边界约束**：确保置信区间在临床范围内

### 3. 参数拟合算法

#### 3.1 最小二乘法实现

**代码实现**：
```python
def fit_parameters(self, bmi_data: np.ndarray, time_data: np.ndarray) -> Dict[str, float]:
    """
    基于新数据拟合参数（便于后续迭代）
    """
    # 对数拟合
    log_bmi = np.log(bmi_data)
    coeffs = np.polyfit(log_bmi, time_data, 1)
    
    new_alpha = coeffs[0]
    new_beta = coeffs[1]
    
    # 更新参数
    self.alpha = new_alpha
    self.beta = new_beta
    
    logger.info(f"参数更新: α={new_alpha:.3f}, β={new_beta:.3f}")
    
    return {
        'alpha': new_alpha,
        'beta': new_beta,
        'gamma': self.gamma,
        'delta': self.delta
    }
```

**算法特点**：
- **对数变换**：ln(BMI)作为自变量
- **线性拟合**：使用numpy.polyfit
- **参数更新**：实时更新模型参数

#### 3.2 模型创建算法

**代码实现**：
```python
def create_empirical_model_from_data(long_df: pd.DataFrame) -> EmpiricalDetectionModel:
    """
    基于实际数据创建经验模型
    """
    # 定义BMI分组
    bins = [20.0, 30.5, 32.7, 34.4, 50.0]
    labels = ['低BMI组', '中BMI组', '高BMI组', '极高BMI组']
    long_df['bmi_group'] = pd.cut(long_df['BMI_used'], bins=bins, labels=labels)
    
    # 计算各组的首次达标时点
    first_hit = long_df[long_df['Y_frac'] > 0.04].groupby(['id', 'bmi_group'])['week'].min().reset_index()
    group_stats = first_hit.groupby('bmi_group')['week'].mean()
    
    # 提取BMI中位数和时点数据
    bmi_data = []
    time_data = []
    
    for group in labels:
        group_data = first_hit[first_hit['bmi_group'] == group]
        if len(group_data) > 0:
            bmi_median = long_df[long_df['bmi_group'] == group]['BMI_used'].median()
            time_mean = group_data['week'].mean()
            bmi_data.append(bmi_median)
            time_data.append(time_mean)
    
    # 创建模型
    model = EmpiricalDetectionModel()
    
    # 拟合参数
    model.fit_parameters(np.array(bmi_data), np.array(time_data))
    
    return model
```

**数据处理流程**：
1. **BMI分组**：使用pandas.cut进行分组
2. **首次达标时点**：筛选Y_frac > 0.04的记录
3. **数据聚合**：计算每组的BMI中位数和时点均值
4. **模型拟合**：使用聚合数据拟合参数

## 📊 性能评估实现

### 1. 评估指标计算

#### 1.1 误差指标实现

**代码实现**：
```python
def evaluate_model(self, bmi_data: np.ndarray, time_data: np.ndarray) -> Dict[str, float]:
    """
    评估模型性能
    """
    predicted_times = [self.predict_optimal_time(bmi) for bmi in bmi_data]
    
    # 计算误差指标
    mae = np.mean(np.abs(np.array(predicted_times) - time_data))
    mse = np.mean((np.array(predicted_times) - time_data) ** 2)
    rmse = np.sqrt(mse)
    
    # 计算相关系数
    correlation = np.corrcoef(predicted_times, time_data)[0, 1]
    
    return {
        'mae': mae,
        'mse': mse,
        'rmse': rmse,
        'correlation': correlation
    }
```

**指标说明**：
- **MAE**：平均绝对误差，衡量预测精度
- **MSE**：均方误差，衡量预测方差
- **RMSE**：均方根误差，与原始数据同量纲
- **相关系数**：衡量预测值与实际值的线性关系

### 2. 分组预测实现

#### 2.1 分组时点预测

**代码实现**：
```python
def predict_group_time(self, bmi_groups: Dict[str, Tuple[float, float]]) -> Dict[str, float]:
    """
    预测BMI分组的检测时点
    """
    group_times = {}
    
    for group_name, (bmi_min, bmi_max) in bmi_groups.items():
        # 使用组内BMI中位数
        bmi_median = (bmi_min + bmi_max) / 2
        optimal_time = self.predict_optimal_time(bmi_median)
        group_times[group_name] = optimal_time
        
    return group_times
```

**实现原理**：
- **中位数策略**：使用组内BMI中位数作为代表值
- **批量预测**：一次性预测所有分组
- **字典返回**：便于后续处理和展示

## 🔄 主程序流程实现

### 1. 数据加载流程

#### 1.1 数据读取实现

**代码实现**：
```python
# 1. 读取数据与配置
logger.info("步骤 1: 读取数据与配置")
long_df, surv_df, report, step1_config = load_step1_products(args.data_dir)
config = load_step2_config(args.config)

logger.info(f"数据摘要: {len(long_df)} 条记录, {long_df['id'].nunique()} 个个体")
```

**数据验证**：
- **记录数量**：检查数据完整性
- **个体数量**：验证数据范围
- **配置加载**：确保参数正确

### 2. 模型创建流程

#### 2.1 模型初始化

**代码实现**：
```python
# 2. 创建经验检测模型
logger.info("步骤 2: 创建经验检测模型")
empirical_model = create_empirical_model_from_data(long_df)

# 显示模型参数
params = empirical_model.get_model_parameters()
logger.info(f"模型参数: α={params['alpha']:.3f}, β={params['beta']:.3f}")
logger.info(f"约束条件: t_min={params['t_min']:.1f}, t_max={params['t_max']:.1f}")
```

**参数显示**：
- **核心参数**：α和β值
- **约束条件**：时点范围
- **日志记录**：便于调试和监控

### 3. 结果生成流程

#### 3.1 w*(b)曲线生成

**代码实现**：
```python
# 3. 生成w*(b)曲线
logger.info("步骤 3: 生成w*(b)曲线")

# 创建BMI网格
bmi_min = long_df['BMI_used'].min()
bmi_max = long_df['BMI_used'].max()
bmi_grid = np.linspace(bmi_min, bmi_max, 40)

# 计算每个BMI点的最优时点
wstar_curve_data = []
for bmi in bmi_grid:
    optimal_time = empirical_model.predict_optimal_time(bmi)
    lower_bound, upper_bound = empirical_model.predict_confidence_interval(bmi)
    
    wstar_curve_data.append({
        'BMI': bmi,
        'w_star': optimal_time,
        'w_star_smooth': optimal_time,
        'min_risk': 0.1,
        'lower_bound': lower_bound,
        'upper_bound': upper_bound
    })

wstar_curve = pd.DataFrame(wstar_curve_data)
```

**实现特点**：
- **网格生成**：使用np.linspace创建均匀网格
- **批量计算**：循环计算每个BMI点
- **置信区间**：同时计算上下界
- **数据结构**：使用字典列表构建DataFrame

#### 3.2 分组结果生成

**代码实现**：
```python
# 4. BMI分组
logger.info("步骤 4: BMI分组")

# 使用经验模型进行分组
bmi_groups = {
    '低BMI组': (20.0, 30.5),
    '中BMI组': (30.5, 32.7),
    '高BMI组': (32.7, 34.4),
    '极高BMI组': (34.4, 50.0)
}

group_times = empirical_model.predict_group_time(bmi_groups)

# 创建分组结果
groups_data = []
for i, (group_name, (bmi_min, bmi_max)) in enumerate(bmi_groups.items(), 1):
    bmi_median = (bmi_min + bmi_max) / 2
    optimal_time = group_times[group_name]
    
    # 计算该组的实际数据统计
    group_mask = (long_df['BMI_used'] >= bmi_min) & (long_df['BMI_used'] < bmi_max)
    group_data = long_df[group_mask]
    n_points = len(group_data)
    
    groups_data.append({
        'group_id': i,
        'bmi_min': bmi_min,
        'bmi_max': bmi_max,
        'bmi_mean': group_data['BMI_used'].mean() if n_points > 0 else bmi_median,
        'n_points': n_points,
        'optimal_time': optimal_time,
        'time_std': 0.0,
        'mean_risk': 0.1
    })

groups_df = pd.DataFrame(groups_data)
```

**分组逻辑**：
- **预定义分组**：使用固定的BMI切点
- **时点预测**：使用模型预测每组的时点
- **统计信息**：计算每组的实际数据统计
- **结果整合**：将所有信息整合到DataFrame

## 📈 输出生成实现

### 1. 报告生成

#### 1.1 文本报告生成

**代码实现**：
```python
# 6. 生成报告
logger.info("步骤 6: 生成报告")

report_content = f"""=== 基于经验数据的理论模型分析报告 ===

1. 模型参数
   - 对数关系: t = {params['alpha']:.3f} × ln(BMI) + {params['beta']:.3f}
   - 个体变异修正系数: {params['gamma']:.3f}
   - BMI偏离修正系数: {params['delta']:.3f}
   - 参考BMI: {params['bmi_ref']:.1f}
   - 时点约束: {params['t_min']:.1f} - {params['t_max']:.1f} 周

2. BMI分组推荐
"""
        
for _, row in groups_df.iterrows():
    report_content += f"   组 {row['group_id']}: BMI [{row['bmi_min']:.1f}, {row['bmi_max']:.1f}), 推荐时点 {row['optimal_time']:.1f} 周\n"
```

**报告内容**：
- **模型参数**：显示所有关键参数
- **分组推荐**：显示每组的推荐时点
- **性能指标**：显示模型性能
- **数学公式**：显示核心数学公式

### 2. 文件保存

#### 2.1 结果保存实现

**代码实现**：
```python
# 7. 保存结果
logger.info("步骤 7: 保存结果")

# 确保输出目录存在
os.makedirs(args.output_dir, exist_ok=True)

# 保存文件
wstar_curve.to_csv(f"{args.output_dir}/p2_wstar_curve.csv", index=False)
groups_df.to_csv(f"{args.output_dir}/p2_group_recommendation.csv", index=False)

with open(f"{args.output_dir}/p2_report.txt", 'w', encoding='utf-8') as f:
    f.write(report_content)

# 保存模型参数
import yaml
with open(f"{args.output_dir}/empirical_model_params.yaml", 'w', encoding='utf-8') as f:
    yaml.dump(params, f, default_flow_style=False, allow_unicode=True)
```

**保存策略**：
- **CSV文件**：使用pandas.to_csv保存数据
- **文本文件**：使用文件写入保存报告
- **YAML文件**：使用yaml.dump保存参数
- **目录创建**：使用os.makedirs确保目录存在

## 🔧 工具函数实现

### 1. 数据加载工具

#### 1.1 数据读取函数

**代码实现**：
```python
def load_step1_products(data_dir: str) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, dict]:
    """
    从指定目录加载Step1产物
    """
    # 读取长表数据
    long_df = pd.read_csv(f"{data_dir}/step1_long_records.csv")
    
    # 读取生存数据
    surv_df = pd.read_csv(f"{data_dir}/step1_surv_dat_fit.csv")
    
    # 读取处理报告
    report = pd.read_csv(f"{data_dir}/step1_report.csv")
    
    # 读取Step1配置
    with open(f"{data_dir}/step1_config.yaml", 'r', encoding='utf-8') as f:
        step1_config = yaml.safe_load(f)
    
    return long_df, surv_df, report, step1_config
```

**实现特点**：
- **路径拼接**：使用f-string构建文件路径
- **异常处理**：文件不存在时抛出异常
- **类型提示**：使用Tuple类型提示
- **编码处理**：指定UTF-8编码

### 2. 配置加载工具

#### 2.1 配置文件读取

**代码实现**：
```python
def load_step2_config(config_path: str) -> dict:
    """
    加载Step2配置文件
    """
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    logger.info(f"Step2 配置读取完成")
    return config
```

**实现特点**：
- **YAML解析**：使用yaml.safe_load安全解析
- **日志记录**：记录配置加载状态
- **错误处理**：文件不存在时抛出异常

## 🎯 代码优化策略

### 1. 性能优化

#### 1.1 向量化计算

**优化前**：
```python
predicted_times = []
for bmi in bmi_data:
    predicted_times.append(self.predict_optimal_time(bmi))
```

**优化后**：
```python
predicted_times = [self.predict_optimal_time(bmi) for bmi in bmi_data]
```

**优化效果**：
- **列表推导式**：提高代码可读性
- **内存效率**：减少中间变量
- **执行速度**：Python解释器优化

#### 1.2 缓存机制

**代码实现**：
```python
from functools import lru_cache

@lru_cache(maxsize=128)
def predict_base_time_cached(self, BMI: float) -> float:
    """带缓存的时点预测"""
    return self.predict_base_time(BMI)
```

**优化效果**：
- **重复计算**：避免相同输入的重复计算
- **内存使用**：LRU缓存控制内存使用
- **性能提升**：显著提高重复调用性能

### 2. 错误处理

#### 2.1 输入验证

**代码实现**：
```python
def predict_optimal_time(self, BMI: float, sigma: float = 0.0) -> float:
    """预测最优检测时点"""
    # 输入验证
    if not isinstance(BMI, (int, float)):
        raise TypeError("BMI必须是数值类型")
    
    if BMI <= 0:
        raise ValueError("BMI必须大于0")
    
    if not isinstance(sigma, (int, float)):
        raise TypeError("sigma必须是数值类型")
    
    if sigma < 0:
        raise ValueError("sigma不能为负数")
    
    # 正常计算逻辑
    # ...
```

**验证策略**：
- **类型检查**：确保输入类型正确
- **范围检查**：确保输入值在合理范围
- **异常抛出**：提供清晰的错误信息

#### 2.2 异常处理

**代码实现**：
```python
try:
    # 模型计算
    result = model.predict_optimal_time(bmi)
except ValueError as e:
    logger.error(f"输入验证失败: {e}")
    return None
except Exception as e:
    logger.error(f"计算失败: {e}")
    return None
```

**处理策略**：
- **特定异常**：针对不同异常类型处理
- **日志记录**：记录错误信息便于调试
- **优雅降级**：返回默认值而不是崩溃

### 3. 代码可维护性

#### 3.1 模块化设计

**代码结构**：
```python
# 主程序
def main():
    # 数据加载
    data = load_data()
    
    # 模型创建
    model = create_model(data)
    
    # 结果生成
    results = generate_results(model)
    
    # 结果保存
    save_results(results)

# 工具函数
def load_data():
    # 数据加载逻辑
    pass

def create_model(data):
    # 模型创建逻辑
    pass
```

**设计原则**：
- **单一职责**：每个函数只做一件事
- **低耦合**：函数间依赖最小化
- **高内聚**：相关功能集中在一起

#### 3.2 配置化设计

**代码实现**：
```python
class EmpiricalDetectionModel:
    def __init__(self, config: dict = None):
        if config is None:
            config = self._get_default_config()
        
        self.alpha = config.get('alpha', 11.358)
        self.beta = config.get('beta', -24.261)
        # ...
    
    def _get_default_config(self):
        return {
            'alpha': 11.358,
            'beta': -24.261,
            'gamma': 0.5,
            'delta': 0.01,
            'bmi_ref': 30.0,
            't_min': 12.0,
            't_max': 25.0
        }
```

**配置优势**：
- **参数化**：所有参数可配置
- **默认值**：提供合理的默认配置
- **灵活性**：支持不同场景的配置

## 📚 总结

### 1. 代码设计原则

- **数学严谨性**：每个算法都有数学公式支撑
- **模块化设计**：功能独立，便于维护
- **可扩展性**：支持新功能和参数
- **可配置性**：所有参数都可调整

### 2. 实现特点

- **向量化计算**：使用numpy提高性能
- **异常处理**：完善的错误处理机制
- **日志记录**：详细的执行日志
- **类型提示**：提高代码可读性

### 3. 性能优化

- **缓存机制**：避免重复计算
- **批量处理**：提高处理效率
- **内存优化**：合理使用内存
- **算法优化**：选择高效算法

这个经验建模系统通过精心设计的代码架构和算法实现，为NIPT检测时点预测提供了科学、可靠、高效的解决方案。
